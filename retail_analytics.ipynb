{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Retail Analytics (PySpark)\n",
                "\n",
                "This notebook analyzes the retail dataset using PySpark to answer business questions.\n",
                "Data is pre-processed by `prepare_data.py`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pyspark.sql import SparkSession\n",
                "from pyspark.sql.functions import col, sum as _sum, window, avg, countDistinct, lit, when, date_format, count, desc, row_number\n",
                "from pyspark.sql.window import Window\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import os\n",
                "\n",
                "# Initialize Spark Session\n",
                "spark = SparkSession.builder.appName(\"RetailAnalytics\").getOrCreate()\n",
                "spark.sparkContext.setLogLevel(\"ERROR\")\n",
                "\n",
                "# Set plot style\n",
                "sns.set_theme(style=\"whitegrid\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Processed Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "PROCESSED_DIR = 'data/processed_transactions'\n",
                "PROMO_PROCESSED_DIR = 'data/processed_promotions'\n",
                "\n",
                "# Load Parquet data\n",
                "df = spark.read.parquet(PROCESSED_DIR)\n",
                "df_promotions = spark.read.parquet(PROMO_PROCESSED_DIR)\n",
                "\n",
                "print(\"Total records:\", df.count())\n",
                "df.printSchema()\n",
                "df.show(5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Analysis: Weekly Purchase Data for Customers\n",
                "Question: What are the purchase data for customers displayed weekly?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Group by customer and week\n",
                "# We use 'window' function on the date column for weekly grouping.\n",
                "# '1 week' duration.\n",
                "\n",
                "weekly_sales = df.groupBy(\n",
                "    \"customer_name\",\n",
                "    window(col(\"date\"), \"1 week\")\n",
                ").agg(\n",
                "    _sum(\"price_paid\").alias(\"total_spend\")\n",
                ")\n",
                "\n",
                "# Extract start date from window for cleaner sorting/display\n",
                "weekly_sales = weekly_sales.withColumn(\"week_start\", col(\"window.start\")) \\\n",
                "                           .drop(\"window\")\n",
                "\n",
                "# Sort\n",
                "weekly_sales = weekly_sales.orderBy(\"customer_name\", \"week_start\")\n",
                "\n",
                "weekly_sales.show(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert to Pandas for visualization\n",
                "pdf_weekly_sales = weekly_sales.toPandas()\n",
                "\n",
                "# Visualize for a few top customers\n",
                "top_customers = pdf_weekly_sales.groupby('customer_name')['total_spend'].sum().nlargest(5).index\n",
                "\n",
                "plt.figure(figsize=(12, 6))\n",
                "sns.lineplot(data=pdf_weekly_sales[pdf_weekly_sales['customer_name'].isin(top_customers)], \n",
                "             x='week_start', y='total_spend', hue='customer_name', marker='o')\n",
                "plt.title('Weekly Spend for Top 5 Customers')\n",
                "plt.xlabel('Week')\n",
                "plt.ylabel('Total Spend ($)')\n",
                "plt.legend(title='Customer')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Classification: Fast, Medium, Slow Items & Stores\n",
                "Group items and stores based on average weekly sales.\n",
                "- **Fast**: Top 33%\n",
                "- **Medium**: Middle 33%\n",
                "- **Slow**: Bottom 33%"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def classify_entity(df, entity_col, entity_name_col, metric_col='price_paid'):\n",
                "    # 1. Calculate weekly sales per entity\n",
                "    weekly_entity_sales = df.groupBy(\n",
                "        entity_col,\n",
                "        entity_name_col,\n",
                "        window(col(\"date\"), \"1 week\")\n",
                "    ).agg(\n",
                "        _sum(metric_col).alias(\"weekly_sales\")\n",
                "    )\n",
                "    \n",
                "    # 2. Calculate average weekly sales per entity\n",
                "    avg_weekly_sales = weekly_entity_sales.groupBy(entity_col, entity_name_col) \\\n",
                "        .agg(avg(\"weekly_sales\").alias(\"avg_weekly_sales\"))\n",
                "    \n",
                "    # 3. Determine thresholds (33rd and 66th percentiles)\n",
                "    # We use approxQuantile for efficiency\n",
                "    quantiles = avg_weekly_sales.approxQuantile(\"avg_weekly_sales\", [0.33, 0.66], 0.01)\n",
                "    low_threshold = quantiles[0]\n",
                "    high_threshold = quantiles[1]\n",
                "    \n",
                "    print(f\"Classification Thresholds for {entity_name_col}:\")\n",
                "    print(f\"  Slow < {low_threshold:.2f}\")\n",
                "    print(f\"  {low_threshold:.2f} <= Medium <= {high_threshold:.2f}\")\n",
                "    print(f\"  Fast > {high_threshold:.2f}\")\n",
                "    \n",
                "    # 4. Classify\n",
                "    classified_df = avg_weekly_sales.withColumn(\n",
                "        \"classification\",\n",
                "        when(col(\"avg_weekly_sales\") > high_threshold, \"Fast\")\n",
                "        .when(col(\"avg_weekly_sales\") < low_threshold, \"Slow\")\n",
                "        .otherwise(\"Medium\")\n",
                "    )\n",
                "    \n",
                "    return classified_df.orderBy(col(\"avg_weekly_sales\").desc())\n",
                "\n",
                "# Classify Products\n",
                "print(\"--- Product Classification ---\")\n",
                "classified_products = classify_entity(df, \"product_id\", \"product_name\")\n",
                "classified_products.show(10)\n",
                "\n",
                "# Classify Shops\n",
                "print(\"\\n--- Shop Classification ---\")\n",
                "classified_shops = classify_entity(df, \"shop_id\", \"shop_name\")\n",
                "classified_shops.show(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Promotion Impact Analysis\n",
                "Analyze the impact of promotions on sales.\n",
                "\n",
                "**Questions:**\n",
                "1.  Which items experienced the biggest sale increase during promotions?\n",
                "2.  Are there stores that have higher promotion reaction?\n",
                "3.  Is there any significant difference between promotion impacts of the Fast versus Slow items?\n",
                "4.  Is there any significant difference between promotion impacts of the Fast versus Slow stores?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Flag Transactions as Promo or Regular\n",
                "# Join transactions with promotions based on product_id and date range\n",
                "\n",
                "df_with_promo = df.alias(\"t\").join(\n",
                "    df_promotions.alias(\"p\"),\n",
                "    (col(\"t.product_id\") == col(\"p.product_id\")) &\n",
                "    (col(\"t.date\") >= col(\"p.start_date\")) &\n",
                "    (col(\"t.date\") <= col(\"p.end_date\")),\n",
                "    \"left\"\n",
                ").select(\n",
                "    col(\"t.*\"),\n",
                "    when(col(\"p.promotion_id\").isNotNull(), 1).otherwise(0).alias(\"is_promo\")\n",
                ")\n",
                "\n",
                "df_with_promo.show(5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Helper function to calculate lift\n",
                "def calculate_lift(df_input, group_cols):\n",
                "    # Calculate average daily sales for Promo vs Regular periods\n",
                "    # Note: This is a simplified view. Ideally we'd normalize by number of days.\n",
                "    # Here we'll take average sales per transaction as a proxy for \"impact\" or total sales if we assume equal time.\n",
                "    # Better metric: Avg Daily Sales. \n",
                "    \n",
                "    # Let's calculate Total Sales and Count of Days (or Transactions) for Promo vs Regular\n",
                "    stats = df_input.groupBy(group_cols + [\"is_promo\"]).agg(\n",
                "        _sum(\"price_paid\").alias(\"total_sales\"),\n",
                "        countDistinct(\"date\").alias(\"days_active\") # Approximate days with sales\n",
                "    )\n",
                "    \n",
                "    # Pivot to get columns: sales_0 (Regular), sales_1 (Promo)\n",
                "    # We need to handle cases where an item might not have promo sales.\n",
                "    \n",
                "    # Separate Promo and Regular\n",
                "    regular = stats.filter(col(\"is_promo\") == 0).withColumnRenamed(\"total_sales\", \"reg_sales\").withColumnRenamed(\"days_active\", \"reg_days\")\n",
                "    promo = stats.filter(col(\"is_promo\") == 1).withColumnRenamed(\"total_sales\", \"promo_sales\").withColumnRenamed(\"days_active\", \"promo_days\")\n",
                "    \n",
                "    joined = regular.join(promo, group_cols, \"left\")\n",
                "    \n",
                "    # Calculate Avg Daily Sales\n",
                "    joined = joined.withColumn(\"avg_daily_reg\", col(\"reg_sales\") / col(\"reg_days\")) \\\n",
                "                   .withColumn(\"avg_daily_promo\", col(\"promo_sales\") / col(\"promo_days\"))\n",
                "    \n",
                "    # Calculate Lift: (Promo - Regular) / Regular\n",
                "    joined = joined.withColumn(\"lift\", (col(\"avg_daily_promo\") - col(\"avg_daily_reg\")) / col(\"avg_daily_reg\"))\n",
                "    \n",
                "    return joined.orderBy(col(\"lift\").desc())\n",
                "\n",
                "# Q1: Which items experienced the biggest sale increase during promotions?\n",
                "print(\"--- Q1: Item Sales Lift ---\")\n",
                "item_lift = calculate_lift(df_with_promo, [\"product_id\", \"product_name\"])\n",
                "item_lift.select(\"product_name\", \"avg_daily_reg\", \"avg_daily_promo\", \"lift\").show(10)\n",
                "\n",
                "# Q2: Are there stores that have higher promotion reaction?\n",
                "print(\"\\n--- Q2: Store Sales Lift ---\")\n",
                "store_lift = calculate_lift(df_with_promo, [\"shop_id\", \"shop_name\"])\n",
                "store_lift.select(\"shop_name\", \"avg_daily_reg\", \"avg_daily_promo\", \"lift\").show(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Q3: Is there any significant difference between promotion impacts of the Fast versus Slow items?\n",
                "print(\"\\n--- Q3: Fast vs Slow Items Impact ---\")\n",
                "# Join item lift with classification\n",
                "item_impact = item_lift.join(classified_products.select(\"product_id\", \"classification\"), \"product_id\")\n",
                "\n",
                "item_impact_summary = item_impact.groupBy(\"classification\").agg(\n",
                "    avg(\"lift\").alias(\"avg_lift\")\n",
                ").orderBy(\"avg_lift\")\n",
                "\n",
                "item_impact_summary.show()\n",
                "\n",
                "# Q4: Is there any significant difference between promotion impacts of the Fast versus Slow stores?\n",
                "print(\"\\n--- Q4: Fast vs Slow Stores Impact ---\")\n",
                "# Join store lift with classification\n",
                "store_impact = store_lift.join(classified_shops.select(\"shop_id\", \"classification\"), \"shop_id\")\n",
                "\n",
                "store_impact_summary = store_impact.groupBy(\"classification\").agg(\n",
                "    avg(\"lift\").alias(\"avg_lift\")\n",
                ").orderBy(\"avg_lift\")\n",
                "\n",
                "store_impact_summary.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Advanced Insights & Trends\n",
                "Additional insights into returns, customers, geography, and timing.\n",
                "\n",
                "**Questions:**\n",
                "5.  Which product categories have the highest return rate?\n",
                "6.  Who are the top customers by frequency and monetary value?\n",
                "7.  What is the top-selling product category for each store?\n",
                "8.  What is the busiest day of the week?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Q5: Return Rate Analysis by Category\n",
                "print(\"--- Q5: Return Rate by Category ---\")\n",
                "\n",
                "# Return is defined as price_paid < 0\n",
                "category_stats = df.groupBy(\"category\").agg(\n",
                "    count(\"transaction_id\").alias(\"total_txns\"),\n",
                "    _sum(when(col(\"price_paid\") < 0, 1).otherwise(0)).alias(\"return_count\")\n",
                ")\n",
                "\n",
                "category_returns = category_stats.withColumn(\n",
                "    \"return_rate\", col(\"return_count\") / col(\"total_txns\")\n",
                ").orderBy(col(\"return_rate\").desc())\n",
                "\n",
                "category_returns.show()\n",
                "\n",
                "# Visualize\n",
                "pdf_returns = category_returns.toPandas()\n",
                "plt.figure(figsize=(10, 5))\n",
                "sns.barplot(data=pdf_returns, x='category', y='return_rate')\n",
                "plt.title('Return Rate by Product Category')\n",
                "plt.ylabel('Return Rate')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Q6: Customer Segmentation (Frequency & Monetary)\n",
                "print(\"--- Q6: Top Customers (Frequency & Monetary) ---\")\n",
                "\n",
                "customer_metrics = df.groupBy(\"customer_name\").agg(\n",
                "    countDistinct(\"transaction_id\").alias(\"frequency\"),\n",
                "    _sum(\"price_paid\").alias(\"monetary\")\n",
                ").orderBy(col(\"monetary\").desc())\n",
                "\n",
                "customer_metrics.show(10)\n",
                "\n",
                "# Scatter plot\n",
                "pdf_customers = customer_metrics.toPandas()\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.scatterplot(data=pdf_customers, x='frequency', y='monetary', alpha=0.6)\n",
                "plt.title('Customer Segments: Frequency vs Monetary')\n",
                "plt.xlabel('Frequency (Number of Visits)')\n",
                "plt.ylabel('Monetary (Total Spend)')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Q7: Geographic Preferences (Top Category per Store)\n",
                "print(\"--- Q7: Top Category per Store ---\")\n",
                "\n",
                "store_category_sales = df.groupBy(\"shop_name\", \"category\").agg(\n",
                "    _sum(\"price_paid\").alias(\"total_sales\")\n",
                ")\n",
                "\n",
                "window_spec = Window.partitionBy(\"shop_name\").orderBy(col(\"total_sales\").desc())\n",
                "\n",
                "top_categories = store_category_sales.withColumn(\n",
                "    \"rank\", row_number().over(window_spec)\n",
                ").filter(col(\"rank\") == 1).drop(\"rank\")\n",
                "\n",
                "top_categories.orderBy(\"shop_name\").show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Q8: Peak Trading Times (Busiest Day of Week)\n",
                "print(\"--- Q8: Busiest Day of Week ---\")\n",
                "\n",
                "# Extract day of week (E format gives Mon, Tue, etc.)\n",
                "df_with_day = df.withColumn(\"day_of_week\", date_format(col(\"date\"), \"E\"))\n",
                "\n",
                "daily_volume = df_with_day.groupBy(\"day_of_week\").agg(\n",
                "    count(\"transaction_id\").alias(\"txn_count\")\n",
                ").orderBy(col(\"txn_count\").desc())\n",
                "\n",
                "daily_volume.show()\n",
                "\n",
                "# Visualize\n",
                "pdf_daily = daily_volume.toPandas()\n",
                "# Sort by day order for plotting if needed, but simple bar chart works\n",
                "plt.figure(figsize=(10, 5))\n",
                "sns.barplot(data=pdf_daily, x='day_of_week', y='txn_count', order=['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
                "plt.title('Transaction Volume by Day of Week')\n",
                "plt.ylabel('Number of Transactions')\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}